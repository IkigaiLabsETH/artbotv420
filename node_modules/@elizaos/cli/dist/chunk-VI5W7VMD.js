
import { createRequire } from 'module';
const require = createRequire(import.meta.url);

import {
  require_src
} from "./chunk-AOCSN5JE.js";
import {
  execa
} from "./chunk-LIA2BGYJ.js";
import {
  require_main
} from "./chunk-XDVWGVQZ.js";
import {
  logger
} from "./chunk-H473MSWF.js";
import {
  __commonJS,
  __require,
  __toESM
} from "./chunk-567UPUC7.js";

// ../../node_modules/agent-base/dist/helpers.js
var require_helpers = __commonJS({
  "../../node_modules/agent-base/dist/helpers.js"(exports) {
    "use strict";
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __setModuleDefault = exports && exports.__setModuleDefault || (Object.create ? function(o, v) {
      Object.defineProperty(o, "default", { enumerable: true, value: v });
    } : function(o, v) {
      o["default"] = v;
    });
    var __importStar = exports && exports.__importStar || function(mod) {
      if (mod && mod.__esModule) return mod;
      var result = {};
      if (mod != null) {
        for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
      }
      __setModuleDefault(result, mod);
      return result;
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.req = exports.json = exports.toBuffer = void 0;
    var http = __importStar(__require("http"));
    var https = __importStar(__require("https"));
    async function toBuffer(stream) {
      let length = 0;
      const chunks = [];
      for await (const chunk of stream) {
        length += chunk.length;
        chunks.push(chunk);
      }
      return Buffer.concat(chunks, length);
    }
    exports.toBuffer = toBuffer;
    async function json(stream) {
      const buf = await toBuffer(stream);
      const str = buf.toString("utf8");
      try {
        return JSON.parse(str);
      } catch (_err) {
        const err = _err;
        err.message += ` (input: ${str})`;
        throw err;
      }
    }
    exports.json = json;
    function req(url, opts = {}) {
      const href = typeof url === "string" ? url : url.href;
      const req2 = (href.startsWith("https:") ? https : http).request(url, opts);
      const promise = new Promise((resolve, reject) => {
        req2.once("response", resolve).once("error", reject).end();
      });
      req2.then = promise.then.bind(promise);
      return req2;
    }
    exports.req = req;
  }
});

// ../../node_modules/agent-base/dist/index.js
var require_dist = __commonJS({
  "../../node_modules/agent-base/dist/index.js"(exports) {
    "use strict";
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __setModuleDefault = exports && exports.__setModuleDefault || (Object.create ? function(o, v) {
      Object.defineProperty(o, "default", { enumerable: true, value: v });
    } : function(o, v) {
      o["default"] = v;
    });
    var __importStar = exports && exports.__importStar || function(mod) {
      if (mod && mod.__esModule) return mod;
      var result = {};
      if (mod != null) {
        for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
      }
      __setModuleDefault(result, mod);
      return result;
    };
    var __exportStar = exports && exports.__exportStar || function(m, exports2) {
      for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p)) __createBinding(exports2, m, p);
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.Agent = void 0;
    var net = __importStar(__require("net"));
    var http = __importStar(__require("http"));
    var https_1 = __require("https");
    __exportStar(require_helpers(), exports);
    var INTERNAL = Symbol("AgentBaseInternalState");
    var Agent = class extends http.Agent {
      constructor(opts) {
        super(opts);
        this[INTERNAL] = {};
      }
      /**
       * Determine whether this is an `http` or `https` request.
       */
      isSecureEndpoint(options) {
        if (options) {
          if (typeof options.secureEndpoint === "boolean") {
            return options.secureEndpoint;
          }
          if (typeof options.protocol === "string") {
            return options.protocol === "https:";
          }
        }
        const { stack } = new Error();
        if (typeof stack !== "string")
          return false;
        return stack.split("\n").some((l) => l.indexOf("(https.js:") !== -1 || l.indexOf("node:https:") !== -1);
      }
      // In order to support async signatures in `connect()` and Node's native
      // connection pooling in `http.Agent`, the array of sockets for each origin
      // has to be updated synchronously. This is so the length of the array is
      // accurate when `addRequest()` is next called. We achieve this by creating a
      // fake socket and adding it to `sockets[origin]` and incrementing
      // `totalSocketCount`.
      incrementSockets(name) {
        if (this.maxSockets === Infinity && this.maxTotalSockets === Infinity) {
          return null;
        }
        if (!this.sockets[name]) {
          this.sockets[name] = [];
        }
        const fakeSocket = new net.Socket({ writable: false });
        this.sockets[name].push(fakeSocket);
        this.totalSocketCount++;
        return fakeSocket;
      }
      decrementSockets(name, socket) {
        if (!this.sockets[name] || socket === null) {
          return;
        }
        const sockets = this.sockets[name];
        const index = sockets.indexOf(socket);
        if (index !== -1) {
          sockets.splice(index, 1);
          this.totalSocketCount--;
          if (sockets.length === 0) {
            delete this.sockets[name];
          }
        }
      }
      // In order to properly update the socket pool, we need to call `getName()` on
      // the core `https.Agent` if it is a secureEndpoint.
      getName(options) {
        const secureEndpoint = typeof options.secureEndpoint === "boolean" ? options.secureEndpoint : this.isSecureEndpoint(options);
        if (secureEndpoint) {
          return https_1.Agent.prototype.getName.call(this, options);
        }
        return super.getName(options);
      }
      createSocket(req, options, cb) {
        const connectOpts = {
          ...options,
          secureEndpoint: this.isSecureEndpoint(options)
        };
        const name = this.getName(connectOpts);
        const fakeSocket = this.incrementSockets(name);
        Promise.resolve().then(() => this.connect(req, connectOpts)).then((socket) => {
          this.decrementSockets(name, fakeSocket);
          if (socket instanceof http.Agent) {
            try {
              return socket.addRequest(req, connectOpts);
            } catch (err) {
              return cb(err);
            }
          }
          this[INTERNAL].currentSocket = socket;
          super.createSocket(req, options, cb);
        }, (err) => {
          this.decrementSockets(name, fakeSocket);
          cb(err);
        });
      }
      createConnection() {
        const socket = this[INTERNAL].currentSocket;
        this[INTERNAL].currentSocket = void 0;
        if (!socket) {
          throw new Error("No socket was returned in the `connect()` function");
        }
        return socket;
      }
      get defaultPort() {
        return this[INTERNAL].defaultPort ?? (this.protocol === "https:" ? 443 : 80);
      }
      set defaultPort(v) {
        if (this[INTERNAL]) {
          this[INTERNAL].defaultPort = v;
        }
      }
      get protocol() {
        return this[INTERNAL].protocol ?? (this.isSecureEndpoint() ? "https:" : "http:");
      }
      set protocol(v) {
        if (this[INTERNAL]) {
          this[INTERNAL].protocol = v;
        }
      }
    };
    exports.Agent = Agent;
  }
});

// ../../node_modules/https-proxy-agent/dist/parse-proxy-response.js
var require_parse_proxy_response = __commonJS({
  "../../node_modules/https-proxy-agent/dist/parse-proxy-response.js"(exports) {
    "use strict";
    var __importDefault = exports && exports.__importDefault || function(mod) {
      return mod && mod.__esModule ? mod : { "default": mod };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.parseProxyResponse = void 0;
    var debug_1 = __importDefault(require_src());
    var debug = (0, debug_1.default)("https-proxy-agent:parse-proxy-response");
    function parseProxyResponse(socket) {
      return new Promise((resolve, reject) => {
        let buffersLength = 0;
        const buffers = [];
        function read() {
          const b = socket.read();
          if (b)
            ondata(b);
          else
            socket.once("readable", read);
        }
        function cleanup() {
          socket.removeListener("end", onend);
          socket.removeListener("error", onerror);
          socket.removeListener("readable", read);
        }
        function onend() {
          cleanup();
          debug("onend");
          reject(new Error("Proxy connection ended before receiving CONNECT response"));
        }
        function onerror(err) {
          cleanup();
          debug("onerror %o", err);
          reject(err);
        }
        function ondata(b) {
          buffers.push(b);
          buffersLength += b.length;
          const buffered = Buffer.concat(buffers, buffersLength);
          const endOfHeaders = buffered.indexOf("\r\n\r\n");
          if (endOfHeaders === -1) {
            debug("have not received end of HTTP headers yet...");
            read();
            return;
          }
          const headerParts = buffered.toString("ascii").split("\r\n");
          const firstLine = headerParts.shift();
          if (!firstLine) {
            socket.destroy();
            return reject(new Error("No header received from proxy CONNECT response"));
          }
          const firstLineParts = firstLine.split(" ");
          const statusCode = +firstLineParts[1];
          const statusText = firstLineParts.slice(2).join(" ");
          const headers = {};
          for (const header of headerParts) {
            if (!header)
              continue;
            const firstColon = header.indexOf(":");
            if (firstColon === -1) {
              socket.destroy();
              return reject(new Error(`Invalid header from proxy CONNECT response: "${header}"`));
            }
            const key = header.slice(0, firstColon).toLowerCase();
            const value = header.slice(firstColon + 1).trimStart();
            const current = headers[key];
            if (typeof current === "string") {
              headers[key] = [current, value];
            } else if (Array.isArray(current)) {
              current.push(value);
            } else {
              headers[key] = value;
            }
          }
          debug("got proxy server response: %o %o", firstLine, headers);
          cleanup();
          resolve({
            connect: {
              statusCode,
              statusText,
              headers
            },
            buffered
          });
        }
        socket.on("error", onerror);
        socket.on("end", onend);
        read();
      });
    }
    exports.parseProxyResponse = parseProxyResponse;
  }
});

// ../../node_modules/https-proxy-agent/dist/index.js
var require_dist2 = __commonJS({
  "../../node_modules/https-proxy-agent/dist/index.js"(exports) {
    "use strict";
    var __createBinding = exports && exports.__createBinding || (Object.create ? function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    } : function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    });
    var __setModuleDefault = exports && exports.__setModuleDefault || (Object.create ? function(o, v) {
      Object.defineProperty(o, "default", { enumerable: true, value: v });
    } : function(o, v) {
      o["default"] = v;
    });
    var __importStar = exports && exports.__importStar || function(mod) {
      if (mod && mod.__esModule) return mod;
      var result = {};
      if (mod != null) {
        for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
      }
      __setModuleDefault(result, mod);
      return result;
    };
    var __importDefault = exports && exports.__importDefault || function(mod) {
      return mod && mod.__esModule ? mod : { "default": mod };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.HttpsProxyAgent = void 0;
    var net = __importStar(__require("net"));
    var tls = __importStar(__require("tls"));
    var assert_1 = __importDefault(__require("assert"));
    var debug_1 = __importDefault(require_src());
    var agent_base_1 = require_dist();
    var parse_proxy_response_1 = require_parse_proxy_response();
    var debug = (0, debug_1.default)("https-proxy-agent");
    var HttpsProxyAgent2 = class extends agent_base_1.Agent {
      get secureProxy() {
        return isHTTPS(this.proxy.protocol);
      }
      constructor(proxy, opts) {
        super(opts);
        this.options = { path: void 0 };
        this.proxy = typeof proxy === "string" ? new URL(proxy) : proxy;
        this.proxyHeaders = opts?.headers ?? {};
        debug("Creating new HttpsProxyAgent instance: %o", this.proxy.href);
        const host = (this.proxy.hostname || this.proxy.host).replace(/^\[|\]$/g, "");
        const port = this.proxy.port ? parseInt(this.proxy.port, 10) : this.secureProxy ? 443 : 80;
        this.connectOpts = {
          // Attempt to negotiate http/1.1 for proxy servers that support http/2
          ALPNProtocols: ["http/1.1"],
          ...opts ? omit(opts, "headers") : null,
          host,
          port
        };
      }
      /**
       * Called when the node-core HTTP client library is creating a
       * new HTTP request.
       */
      async connect(req, opts) {
        const { proxy, secureProxy } = this;
        if (!opts.host) {
          throw new TypeError('No "host" provided');
        }
        let socket;
        if (secureProxy) {
          debug("Creating `tls.Socket`: %o", this.connectOpts);
          socket = tls.connect(this.connectOpts);
        } else {
          debug("Creating `net.Socket`: %o", this.connectOpts);
          socket = net.connect(this.connectOpts);
        }
        const headers = typeof this.proxyHeaders === "function" ? this.proxyHeaders() : { ...this.proxyHeaders };
        const host = net.isIPv6(opts.host) ? `[${opts.host}]` : opts.host;
        let payload = `CONNECT ${host}:${opts.port} HTTP/1.1\r
`;
        if (proxy.username || proxy.password) {
          const auth = `${decodeURIComponent(proxy.username)}:${decodeURIComponent(proxy.password)}`;
          headers["Proxy-Authorization"] = `Basic ${Buffer.from(auth).toString("base64")}`;
        }
        headers.Host = `${host}:${opts.port}`;
        if (!headers["Proxy-Connection"]) {
          headers["Proxy-Connection"] = this.keepAlive ? "Keep-Alive" : "close";
        }
        for (const name of Object.keys(headers)) {
          payload += `${name}: ${headers[name]}\r
`;
        }
        const proxyResponsePromise = (0, parse_proxy_response_1.parseProxyResponse)(socket);
        socket.write(`${payload}\r
`);
        const { connect, buffered } = await proxyResponsePromise;
        req.emit("proxyConnect", connect);
        this.emit("proxyConnect", connect, req);
        if (connect.statusCode === 200) {
          req.once("socket", resume);
          if (opts.secureEndpoint) {
            debug("Upgrading socket connection to TLS");
            const servername = opts.servername || opts.host;
            return tls.connect({
              ...omit(opts, "host", "path", "port"),
              socket,
              servername: net.isIP(servername) ? void 0 : servername
            });
          }
          return socket;
        }
        socket.destroy();
        const fakeSocket = new net.Socket({ writable: false });
        fakeSocket.readable = true;
        req.once("socket", (s) => {
          debug("Replaying proxy buffer for failed request");
          (0, assert_1.default)(s.listenerCount("data") > 0);
          s.push(buffered);
          s.push(null);
        });
        return fakeSocket;
      }
    };
    HttpsProxyAgent2.protocols = ["http", "https"];
    exports.HttpsProxyAgent = HttpsProxyAgent2;
    function resume(socket) {
      socket.resume();
    }
    function isHTTPS(protocol) {
      return typeof protocol === "string" ? /^https:?$/i.test(protocol) : false;
    }
    function omit(obj, ...keys) {
      const ret = {};
      let key;
      for (key in obj) {
        if (!keys.includes(key)) {
          ret[key] = obj[key];
        }
      }
      return ret;
    }
  }
});

// src/utils/registry/index.ts
import { promises as fs3, existsSync as existsSync2 } from "node:fs";
import os2 from "node:os";
import path3 from "node:path";

// src/utils/get-package-info.ts
import { promises as fs } from "node:fs";
import { existsSync, readFileSync } from "node:fs";
import path from "node:path";
var packageJsonPath = path.join("package.json");
function isMonorepoContext() {
  const possibleMonorepoRoot = path.resolve(process.cwd(), "..", "..");
  const workspacePackageJsonPath = path.join(possibleMonorepoRoot, "package.json");
  if (existsSync(workspacePackageJsonPath)) {
    try {
      const packageJson = JSON.parse(readFileSync(workspacePackageJsonPath, "utf8"));
      return !!packageJson.workspaces;
    } catch (_error) {
      return false;
    }
  }
  return false;
}
async function getLocalPackages() {
  if (!isMonorepoContext()) {
    return [];
  }
  try {
    const packagesDir = path.resolve(process.cwd(), "..", "..");
    const packagesDirEntries = await fs.readdir(path.join(packagesDir, "packages"), {
      withFileTypes: true
    });
    const pluginPackages = packagesDirEntries.filter((entry) => entry.isDirectory() && entry.name.startsWith("plugin-")).map((entry) => `@elizaos/${entry.name}`);
    return pluginPackages;
  } catch (error) {
    logger.warn(`Error getting local packages: ${error}`);
    return [];
  }
}

// src/utils/registry/index.ts
var import_dotenv = __toESM(require_main(), 1);
var import_https_proxy_agent = __toESM(require_dist2(), 1);

// src/utils/github.ts
import { promises as fs2 } from "node:fs";
import os from "node:os";
import path2 from "node:path";
var GITHUB_API_URL = "https://api.github.com";
async function validateGitHubToken(token) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/user`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 200) {
      const userData = await response.json();
      logger.success(`Authenticated as ${userData.login}`);
      return true;
    }
    return false;
  } catch (error) {
    logger.error(`Failed to validate GitHub token: ${error.message}`);
    return false;
  }
}
async function forkExists(token, owner, repo, username) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${username}/${repo}`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    return response.status === 200;
  } catch (error) {
    return false;
  }
}
async function forkRepository(token, owner, repo) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/forks`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 202) {
      const forkData = await response.json();
      logger.success(`Forked ${owner}/${repo} to ${forkData.full_name}`);
      return forkData.full_name;
    }
    logger.error(`Failed to fork repository: ${response.statusText}`);
    return null;
  } catch (error) {
    logger.error(`Failed to fork repository: ${error.message}`);
    return null;
  }
}
async function branchExists(token, owner, repo, branch) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/branches/${branch}`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    return response.status === 200;
  } catch (error) {
    return false;
  }
}
async function createBranch(token, owner, repo, branch, baseBranch = "main") {
  try {
    let baseResponse = await fetch(
      `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/${baseBranch}`,
      {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      }
    );
    if (baseResponse.status !== 200) {
      logger.warn(`Base branch '${baseBranch}' not found, checking for alternative branches...`);
      const branchesResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/branches`, {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      });
      if (branchesResponse.status === 200) {
        const branches = await branchesResponse.json();
        if (branches && branches.length > 0) {
          const alternativeBranch = branches[0].name;
          logger.info(`Using '${alternativeBranch}' as base branch instead`);
          baseResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/${alternativeBranch}`,
            {
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json"
              }
            }
          );
        } else {
          logger.info("No branches found in repository, creating initial commit");
          const blobResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/blobs`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              content: "# Repository initialized by Eliza CLI",
              encoding: "utf-8"
            })
          });
          if (blobResponse.status !== 201) {
            logger.error("Failed to create initial blob");
            return false;
          }
          const blobData = await blobResponse.json();
          const blobSha = blobData.sha;
          const treeResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/trees`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              tree: [
                {
                  path: "README.md",
                  mode: "100644",
                  type: "blob",
                  sha: blobSha
                }
              ]
            })
          });
          if (treeResponse.status !== 201) {
            logger.error("Failed to create initial tree");
            return false;
          }
          const treeData = await treeResponse.json();
          const treeSha = treeData.sha;
          const commitResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/commits`,
            {
              method: "POST",
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json",
                "Content-Type": "application/json"
              },
              body: JSON.stringify({
                message: "Initial commit",
                tree: treeSha
              })
            }
          );
          if (commitResponse.status !== 201) {
            logger.error("Failed to create initial commit");
            return false;
          }
          const commitData = await commitResponse.json();
          const commitSha = commitData.sha;
          const refResponse = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/refs`, {
            method: "POST",
            headers: {
              Authorization: `token ${token}`,
              Accept: "application/vnd.github.v3+json",
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              ref: "refs/heads/main",
              sha: commitSha
            })
          });
          if (refResponse.status !== 201) {
            logger.error("Failed to create main branch");
            return false;
          }
          logger.success("Created main branch with initial commit");
          baseResponse = await fetch(
            `${GITHUB_API_URL}/repos/${owner}/${repo}/git/ref/heads/main`,
            {
              headers: {
                Authorization: `token ${token}`,
                Accept: "application/vnd.github.v3+json"
              }
            }
          );
        }
      }
    }
    if (baseResponse.status !== 200) {
      logger.error(`Failed to get base branch ${baseBranch}: ${baseResponse.statusText}`);
      return false;
    }
    const baseData = await baseResponse.json();
    const sha = baseData.object.sha;
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/git/refs`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        ref: `refs/heads/${branch}`,
        sha
      })
    });
    if (response.status === 201) {
      logger.success(`Created branch ${branch} in ${owner}/${repo}`);
      return true;
    }
    logger.error(`Failed to create branch: ${response.statusText}`);
    return false;
  } catch (error) {
    logger.error(`Failed to create branch: ${error.message}`);
    return false;
  }
}
async function getFileContent(token, owner, repo, path4, branch = "main") {
  try {
    const response = await fetch(
      `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path4}?ref=${branch}`,
      {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      }
    );
    if (response.status === 200) {
      const data = await response.json();
      return Buffer.from(data.content, "base64").toString("utf-8");
    }
    return null;
  } catch (error) {
    return null;
  }
}
async function updateFile(token, owner, repo, path4, content, message, branch = "main") {
  try {
    const existingContent = await getFileContent(token, owner, repo, path4, branch);
    const method = existingContent !== null ? "PUT" : "POST";
    let sha;
    if (existingContent !== null) {
      const response2 = await fetch(
        `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path4}?ref=${branch}`,
        {
          headers: {
            Authorization: `token ${token}`,
            Accept: "application/vnd.github.v3+json"
          }
        }
      );
      if (response2.status === 200) {
        const data = await response2.json();
        sha = data.sha;
      }
    }
    const fileUrl = `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${path4}`;
    logger.info(`Updating file at: ${fileUrl}`);
    const requestBody = {
      message,
      content: Buffer.from(content).toString("base64"),
      branch,
      sha
    };
    logger.info(`Request details: method=${method}, branch=${branch}, has_sha=${!!sha}`);
    const response = await fetch(fileUrl, {
      method,
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify(requestBody)
    });
    if (response.status === 200 || response.status === 201) {
      logger.success(existingContent !== null ? "File updated" : "File created");
      return true;
    }
    const errorBody = await response.text();
    logger.error(`Failed to update file: ${response.status} ${response.statusText}`);
    logger.error(`Response body: ${errorBody}`);
    if (response.status === 404) {
      logger.error(`Repository or path not found: ${owner}/${repo}/${path4}`);
      const repoCheck = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}`, {
        headers: {
          Authorization: `token ${token}`,
          Accept: "application/vnd.github.v3+json"
        }
      });
      if (repoCheck.status === 404) {
        logger.error(`Repository ${owner}/${repo} does not exist or is not accessible`);
      } else {
        logger.info(`Repository exists, but path is likely invalid`);
      }
    }
    return false;
  } catch (error) {
    logger.error(`Error updating file: ${error.message}`);
    return false;
  }
}
async function createPullRequest(token, owner, repo, title, body, head, base = "main") {
  try {
    const response = await fetch(`${GITHUB_API_URL}/repos/${owner}/${repo}/pulls`, {
      method: "POST",
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        title,
        body,
        head,
        base
      })
    });
    if (response.status === 201) {
      const data = await response.json();
      logger.success(`Created pull request: ${data.html_url}`);
      return data.html_url;
    }
    logger.error(`Failed to create pull request: ${response.statusText}`);
    return null;
  } catch (error) {
    logger.error(`Failed to create pull request: ${error.message}`);
    return null;
  }
}
async function getAuthenticatedUser(token) {
  try {
    const response = await fetch(`${GITHUB_API_URL}/user`, {
      headers: {
        Authorization: `token ${token}`,
        Accept: "application/vnd.github.v3+json"
      }
    });
    if (response.status === 200) {
      return await response.json();
    }
    return null;
  } catch (error) {
    return null;
  }
}
async function getGitHubCredentials() {
  try {
    let token = process.env.GITHUB_TOKEN;
    let username = process.env.GITHUB_USERNAME;
    if (!token) {
      const { getGitHubToken: getGitHubToken2 } = await import("./registry-5JHHV7LG.js");
      token = await getGitHubToken2() || void 0;
    }
    if (token) {
      const isValid2 = await validateGitHubToken(token);
      if (isValid2) {
        if (!username) {
          const userInfo = await getAuthenticatedUser(token);
          if (userInfo) {
            username = userInfo.login;
            await saveGitHubCredentials(username, token);
          }
        }
        if (username) {
          logger.info(`\u2713 Using GitHub credentials for ${username}`);
          return { username, token };
        }
      } else {
        logger.warn("Stored GitHub token is invalid, will prompt for new credentials");
      }
    }
    const prompt = await import("./prompts-I4LK5NKX.js");
    const { promptedUsername } = await prompt.default({
      type: "text",
      name: "promptedUsername",
      message: "Enter your GitHub username:",
      validate: (value) => value ? true : "Username is required"
    });
    if (!promptedUsername) {
      return null;
    }
    const { promptedToken } = await prompt.default({
      type: "password",
      name: "promptedToken",
      message: "Enter your GitHub Personal Access Token (with repo, read:org, and workflow scopes):",
      validate: (value) => value ? true : "Token is required"
    });
    if (!promptedToken) {
      return null;
    }
    const isValid = await validateGitHubToken(promptedToken);
    if (!isValid) {
      logger.error("Invalid GitHub token");
      return null;
    }
    await saveGitHubCredentials(promptedUsername, promptedToken);
    logger.success("GitHub credentials saved successfully");
    return { username: promptedUsername, token: promptedToken };
  } catch (error) {
    logger.error(`Error handling GitHub credentials: ${error.message}`);
    return null;
  }
}
async function saveGitHubCredentials(username, token) {
  try {
    process.env.GITHUB_USERNAME = username;
    process.env.GITHUB_TOKEN = token;
    const { setGitHubToken: setGitHubToken2 } = await import("./registry-5JHHV7LG.js");
    await setGitHubToken2(token);
    const envFile = path2.join(os.homedir(), ".eliza", ".env");
    try {
      let envContent = await fs2.readFile(envFile, "utf-8");
      const usernameRegex = /^GITHUB_USERNAME=.*$/m;
      if (usernameRegex.test(envContent)) {
        envContent = envContent.replace(usernameRegex, `GITHUB_USERNAME=${username}`);
      } else {
        if (!envContent.endsWith("\n")) envContent += "\n";
        envContent += `GITHUB_USERNAME=${username}
`;
      }
      await fs2.writeFile(envFile, envContent);
    } catch (error) {
      logger.debug(`Error updating username in .env: ${error.message}`);
    }
  } catch (error) {
    logger.error(`Failed to save GitHub credentials: ${error.message}`);
  }
}
async function ensureDirectory(token, owner, repo, directoryPath, branch = "main") {
  try {
    try {
      const response = await fetch(
        `${GITHUB_API_URL}/repos/${owner}/${repo}/contents/${directoryPath}?ref=${branch}`,
        {
          headers: {
            Authorization: `token ${token}`,
            Accept: "application/vnd.github.v3+json"
          }
        }
      );
      if (response.status === 200) {
        logger.info(`Directory ${directoryPath} already exists`);
        return true;
      }
    } catch (error) {
      logger.info(`Directory ${directoryPath} doesn't exist, creating it`);
    }
    const placeholderPath = `${directoryPath}/.gitkeep`;
    const result = await updateFile(
      token,
      owner,
      repo,
      placeholderPath,
      "",
      // Empty content for placeholder
      `Create directory: ${directoryPath}`,
      branch
    );
    if (result) {
      logger.success(`Created directory: ${directoryPath}`);
      return true;
    }
    logger.error(`Failed to create directory: ${directoryPath}`);
    return false;
  } catch (error) {
    logger.error(`Error creating directory: ${error.message}`);
    return false;
  }
}

// src/utils/registry/constants.ts
var REGISTRY_URL = "https://raw.githubusercontent.com/elizaos/registry/refs/heads/main/index.json";

// src/utils/registry/index.ts
var ELIZA_DIR = path3.join(os2.homedir(), ".eliza");
var REGISTRY_SETTINGS_FILE = path3.join(ELIZA_DIR, "registrysettings.json");
var ENV_FILE = path3.join(ELIZA_DIR, ".env");
var REGISTRY_CACHE_FILE = path3.join(ELIZA_DIR, "registry-cache.json");
var REQUIRED_ENV_VARS = ["GITHUB_TOKEN"];
var REQUIRED_SETTINGS = ["defaultRegistry"];
async function ensureElizaDir() {
  try {
    await fs3.mkdir(ELIZA_DIR, { recursive: true });
  } catch (error) {
  }
}
async function getRegistrySettings() {
  await ensureElizaDir();
  try {
    const content = await fs3.readFile(REGISTRY_SETTINGS_FILE, "utf-8");
    return JSON.parse(content);
  } catch (error) {
    return {
      defaultRegistry: "elizaos/registry"
    };
  }
}
async function saveRegistrySettings(settings) {
  await ensureElizaDir();
  await fs3.writeFile(REGISTRY_SETTINGS_FILE, JSON.stringify(settings, null, 2));
}
async function getEnvVar(key) {
  try {
    const envContent = await fs3.readFile(ENV_FILE, "utf-8");
    const env = import_dotenv.default.parse(envContent);
    return env[key];
  } catch (error) {
    return void 0;
  }
}
async function setEnvVar(key, value) {
  await ensureElizaDir();
  let envContent = "";
  try {
    envContent = await fs3.readFile(ENV_FILE, "utf-8");
  } catch (error) {
  }
  const env = import_dotenv.default.parse(envContent);
  env[key] = value;
  const newContent = Object.entries(env).map(([k, v]) => `${k}=${v}`).join("\n");
  await fs3.writeFile(ENV_FILE, newContent);
}
async function getGitHubToken() {
  try {
    const envPath = ENV_FILE;
    if (existsSync2(envPath)) {
      const envContent = await fs3.readFile(envPath, "utf-8");
      const env = import_dotenv.default.parse(envContent);
      return env.GITHUB_TOKEN;
    }
  } catch (error) {
    logger.debug(`Error reading GitHub token: ${error.message}`);
  }
  return void 0;
}
async function setGitHubToken(token) {
  await ensureElizaDir();
  try {
    let envContent = "";
    try {
      if (existsSync2(ENV_FILE)) {
        envContent = await fs3.readFile(ENV_FILE, "utf-8");
      }
    } catch (error) {
      envContent = "# Eliza environment variables\n\n";
    }
    const env = import_dotenv.default.parse(envContent);
    env.GITHUB_TOKEN = token;
    let newContent = "";
    for (const [key, value] of Object.entries(env)) {
      newContent += `${key}=${value}
`;
    }
    await fs3.writeFile(ENV_FILE, newContent);
    process.env.GITHUB_TOKEN = token;
    logger.debug("GitHub token saved successfully");
  } catch (error) {
    logger.error(`Failed to save GitHub token: ${error.message}`);
  }
}
var agent = process.env.https_proxy ? new import_https_proxy_agent.HttpsProxyAgent(process.env.https_proxy) : void 0;
var DEFAULT_REGISTRY = {
  "@elizaos/plugin-anthropic": "elizaos/plugin-anthropic",
  "@elizaos/plugin-discord": "elizaos/plugin-discord",
  "@elizaos/plugin-elevenlabs": "elizaos/plugin-elevenlabs",
  "@elizaos/plugin-local-ai": "elizaos/plugin-local-ai",
  "@elizaos/plugin-openai": "elizaos/plugin-openai",
  "@elizaos/plugin-solana": "elizaos/plugin-solana",
  "@elizaos/plugin-sql": "elizaos/plugin-sql",
  "@elizaos/plugin-starter": "elizaos/plugin-starter",
  "@elizaos/plugin-tee": "elizaos/plugin-tee",
  "@elizaos/plugin-telegram": "elizaos/plugin-telegram",
  "@elizaos/plugin-twitter": "elizaos/plugin-twitter"
};
var RAW_REGISTRY_URL = "https://raw.githubusercontent.com/elizaOS/registry/refs/heads/main/index.json";
async function saveRegistryCache(registry) {
  try {
    await ensureElizaDir();
    await fs3.writeFile(REGISTRY_CACHE_FILE, JSON.stringify(registry, null, 2));
    logger.debug("Registry cache saved successfully");
  } catch (error) {
    logger.debug(`Failed to save registry cache: ${error.message}`);
  }
}
async function getLocalRegistryIndex() {
  try {
    logger.debug("Fetching registry from public GitHub URL");
    const response = await fetch(RAW_REGISTRY_URL);
    if (response.ok) {
      const rawData = await response.json();
      const result = {};
      if (typeof rawData === "object" && rawData !== null) {
        for (const [key, value] of Object.entries(rawData)) {
          if (typeof value === "string") {
            result[key] = value;
          }
        }
        await saveRegistryCache(result);
        logger.debug("Successfully fetched registry from public GitHub URL");
        return result;
      }
    }
  } catch (error) {
    logger.debug(`Failed to fetch registry from public URL: ${error.message}`);
  }
  try {
    if (existsSync2(REGISTRY_CACHE_FILE)) {
      const cacheContent = await fs3.readFile(REGISTRY_CACHE_FILE, "utf-8");
      const cachedRegistry = JSON.parse(cacheContent);
      logger.debug("Using cached registry index");
      return cachedRegistry;
    }
  } catch (error) {
    logger.debug(`Failed to read registry cache: ${error.message}`);
  }
  if (await isMonorepoContext()) {
    try {
      const localPackages = await getLocalPackages();
      const localRegistry = {};
      for (const pkgName of localPackages) {
        if (pkgName.includes("plugin-")) {
          const repoName = pkgName.replace("@elizaos/", "");
          localRegistry[pkgName] = `elizaos/${repoName}`;
        }
      }
      return { ...DEFAULT_REGISTRY, ...localRegistry };
    } catch (error) {
      logger.debug(`Failed to discover local plugins: ${error.message}`);
    }
  }
  return DEFAULT_REGISTRY;
}
async function getRegistryIndex() {
  const settings = await getRegistrySettings();
  const credentials = await getGitHubCredentials();
  if (!credentials) {
    logger.error("GitHub credentials not found. Please run login first.");
    process.exit(1);
  }
  const [owner, repo] = settings.defaultRegistry.split("/");
  const url = `https://api.github.com/repos/${owner}/${repo}/contents/index.json`;
  const response = await fetch(url, {
    headers: {
      Authorization: `token ${credentials.token}`,
      Accept: "application/vnd.github.v3.raw"
    }
  });
  if (!response.ok) {
    throw new Error(`Failed to fetch registry index: ${response.statusText}`);
  }
  const data = await response.json();
  if (typeof data !== "object" || data === null) {
    throw new Error("Invalid registry index format");
  }
  const result = {};
  for (const [key, value] of Object.entries(data)) {
    if (typeof value === "string") {
      result[key] = value;
    }
  }
  return result;
}
async function getPluginRepository(pluginName) {
  try {
    const registry = await getLocalRegistryIndex();
    if (registry[pluginName]) {
      return registry[pluginName];
    }
    const metadata = await getPluginMetadata(pluginName);
    return metadata?.repository || null;
  } catch (error) {
    logger.debug(`Error getting plugin repository for ${pluginName}: ${error.message}`);
    try {
      const metadata = await getPluginMetadata(pluginName);
      return metadata?.repository || null;
    } catch (fallbackError) {
      logger.error(`Failed to get plugin repository: ${fallbackError.message}`);
      return null;
    }
  }
}
async function repoHasBranch(repoUrl, branchName) {
  try {
    const { stdout } = await execa("git", ["ls-remote", "--heads", repoUrl, branchName]);
    return stdout.includes(branchName);
  } catch (error) {
    logger.warn(`Failed to check for branch ${branchName} in ${repoUrl}: ${error.message}`);
    return false;
  }
}
async function getBestBranch(repoUrl) {
  if (await repoHasBranch(repoUrl, "v2")) {
    return "v2";
  }
  if (await repoHasBranch(repoUrl, "v2-develop")) {
    return "v2-develop";
  }
  return "main";
}
async function listPluginsByType(type) {
  const registry = await getRegistryIndex();
  return Object.keys(registry).filter((name) => !type || name.includes(type)).sort();
}
async function getPluginMetadata(pluginName) {
  const settings = await getRegistrySettings();
  const credentials = await getGitHubCredentials();
  if (!credentials) {
    logger.error("GitHub credentials not found. Please run login first.");
    process.exit(1);
  }
  const [owner, repo] = settings.defaultRegistry.split("/");
  const normalizedName = pluginName.replace(/^@elizaos\//, "");
  const url = `https://api.github.com/repos/${owner}/${repo}/contents/packages/${normalizedName}.json`;
  try {
    const response = await fetch(url, {
      headers: {
        Authorization: `token ${credentials.token}`,
        Accept: "application/vnd.github.v3.raw"
      }
    });
    if (!response.ok) {
      if (response.status === 404) {
        return null;
      }
      throw new Error(`Failed to fetch plugin metadata: ${response.statusText}`);
    }
    const data = await response.json();
    if (typeof data !== "object" || data === null) {
      throw new Error("Invalid plugin metadata format");
    }
    const metadata = data;
    if (!metadata.name || !metadata.description || !metadata.author || !metadata.repository || !metadata.versions || !metadata.latestVersion || !metadata.runtimeVersion || !metadata.maintainer) {
      throw new Error("Invalid plugin metadata: missing required fields");
    }
    return metadata;
  } catch (error) {
    logger.error("Failed to fetch plugin metadata:", error);
    return null;
  }
}
async function getPluginVersion(pluginName, version) {
  const metadata = await getPluginMetadata(pluginName);
  if (!metadata) {
    return null;
  }
  if (!version) {
    return metadata.latestVersion;
  }
  if (!metadata.versions.includes(version)) {
    return null;
  }
  return version;
}
async function getPluginTags(pluginName) {
  const metadata = await getPluginMetadata(pluginName);
  return metadata?.tags || [];
}
async function getPluginCategories(pluginName) {
  const metadata = await getPluginMetadata(pluginName);
  return metadata?.categories || [];
}
async function getAvailableDatabases() {
  const registry = await getRegistryIndex();
  return Object.keys(registry).filter((name) => name.includes("database-")).sort();
}
async function getPackageDetails(packageName) {
  try {
    const normalizedName = packageName.replace(/^@elizaos\//, "");
    const packageUrl = `${REGISTRY_URL.replace("index.json", "")}packages/${normalizedName}.json`;
    const requestOptions = {};
    if (process.env.https_proxy) {
      requestOptions.agent = new import_https_proxy_agent.HttpsProxyAgent(process.env.https_proxy);
    }
    const response = await fetch(packageUrl, requestOptions);
    if (response.status !== 200) {
      return null;
    }
    const text = await response.text();
    try {
      return JSON.parse(text);
    } catch {
      logger.warn(`Invalid JSON response received from registry for package ${packageName}:`, text);
      return null;
    }
  } catch (error) {
    logger.warn(`Failed to fetch package details from registry: ${error.message}`);
    return null;
  }
}
async function getBestPluginVersion(packageName, runtimeVersion) {
  const packageDetails = await getPackageDetails(packageName);
  if (!packageDetails || !packageDetails.versions || packageDetails.versions.length === 0) {
    return null;
  }
  if (packageDetails.runtimeVersion === runtimeVersion) {
    return packageDetails.latestVersion;
  }
  const [runtimeMajor, runtimeMinor, runtimePatch] = runtimeVersion.split(".").map(Number);
  const [packageMajor, packageMinor, packagePatch] = packageDetails.runtimeVersion.split(".").map(Number);
  if (runtimeMajor !== packageMajor) {
    logger.warn(
      `Plugin ${packageName} was built for runtime v${packageDetails.runtimeVersion}, but you're using v${runtimeVersion}`
    );
    logger.warn("This may cause compatibility issues.");
    return packageDetails.latestVersion;
  }
  if (runtimeMinor !== packageMinor) {
    logger.warn(
      `Plugin ${packageName} was built for runtime v${packageDetails.runtimeVersion}, you're using v${runtimeVersion}`
    );
  }
  return packageDetails.latestVersion;
}
async function checkDataDir() {
  const status = {
    exists: false,
    env: {
      exists: false,
      missingKeys: [...REQUIRED_ENV_VARS],
      hasAllKeys: false
    },
    settings: {
      exists: false,
      missingKeys: [...REQUIRED_SETTINGS],
      hasAllKeys: false
    }
  };
  try {
    await fs3.access(ELIZA_DIR);
    status.exists = true;
  } catch {
    return status;
  }
  try {
    const envContent = await fs3.readFile(ENV_FILE, "utf-8");
    const env = import_dotenv.default.parse(envContent);
    status.env.exists = true;
    status.env.missingKeys = REQUIRED_ENV_VARS.filter((key) => !env[key]);
    status.env.hasAllKeys = status.env.missingKeys.length === 0;
  } catch {
  }
  try {
    const settingsContent = await fs3.readFile(REGISTRY_SETTINGS_FILE, "utf-8");
    const settings = JSON.parse(settingsContent);
    status.settings.exists = true;
    status.settings.missingKeys = REQUIRED_SETTINGS.filter((key) => !(key in settings));
    status.settings.hasAllKeys = status.settings.missingKeys.length === 0;
  } catch {
  }
  return status;
}
async function initializeDataDir() {
  await ensureElizaDir();
  try {
    await fs3.access(ENV_FILE);
  } catch {
    await fs3.writeFile(ENV_FILE, "");
  }
  try {
    await fs3.access(REGISTRY_SETTINGS_FILE);
  } catch {
    await saveRegistrySettings({
      defaultRegistry: "elizaos/registry"
    });
  }
}
async function validateDataDir() {
  const status = await checkDataDir();
  if (!status.exists) {
    logger.warn("ElizaOS data directory not found. Initializing...");
    await initializeDataDir();
    return false;
  }
  let isValid = true;
  if (!status.env.exists) {
    logger.warn(".env file not found");
    isValid = false;
  } else if (!status.env.hasAllKeys) {
    logger.warn(`Missing environment variables: ${status.env.missingKeys.join(", ")}`);
    isValid = false;
  }
  if (!status.settings.exists) {
    logger.warn("Registry settings file not found");
    isValid = false;
  } else if (!status.settings.hasAllKeys) {
    logger.warn(`Missing settings: ${status.settings.missingKeys.join(", ")}`);
    isValid = false;
  }
  return isValid;
}

export {
  ensureElizaDir,
  getRegistrySettings,
  saveRegistrySettings,
  getEnvVar,
  setEnvVar,
  getGitHubToken,
  setGitHubToken,
  saveRegistryCache,
  getLocalRegistryIndex,
  getRegistryIndex,
  getPluginRepository,
  repoHasBranch,
  getBestBranch,
  listPluginsByType,
  getPluginMetadata,
  getPluginVersion,
  getPluginTags,
  getPluginCategories,
  getAvailableDatabases,
  getPackageDetails,
  getBestPluginVersion,
  checkDataDir,
  initializeDataDir,
  validateDataDir,
  forkExists,
  forkRepository,
  branchExists,
  createBranch,
  getFileContent,
  updateFile,
  createPullRequest,
  getGitHubCredentials,
  ensureDirectory
};
